install.packages("UsingR")
library(UsingR)
library(manipulate)
z<-x*w
mean(z)
library(swirl)
swirl()
plot(child~parent, galton)
plot(jitter(child,4)~ parent, glaton)
plot(jitter(child,4)~ parent, galton)
regrline<-lm(child~parent, galton)
abline(regrline, lwd=3, col="red")
summary(regrline)
regrline<-lm(child~parent, galton)
fit<-lm(child~parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galtron$parent)
cov(fit$residuals, galton$parent)
ols.ic<-fit$coef[1]
ols.slope<-fit$coef[2]
#Here are the vectors of variations or tweaks
sltweak <- c(.01, .02, .03, -.01, -.02, -.03) #one for the slope
ictweak <- c(.1, .2, .3, -.1, -.2, -.3)  #one for the intercept
lhs <- numeric()
rhs <- numeric()
#left side of eqn is the sum of squares of residuals of the tweaked regression line
for (n in 1:6) lhs[n] <- sqe(ols.slope+sltweak[n],ols.ic+ictweak[n])
#right side of eqn is the sum of squares of original residuals + sum of squares of two tweaks
for (n in 1:6) rhs[n] <- sqe(ols.slope,ols.ic) + sum(est(sltweak[n],ictweak[n])^2)
diff<-lhs-rhs
lhs-rhs
all.equal(lhs,rhs)
varChild<-var(child)
varChild<-var(y)
varChild<-var(galton$child)
varRes<-var(fit$residuals)
varEst<-est(ols.slope,ols.ic)
varEst<-var(est(ols.slope,ols.ic))
all.equal(varChild,varRes+varEst)
efit<-lm(accel~mag+dist,attenu)
mean(efit)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor, gch_nor)
l_nor<-lm(gch_nor~gph_nor)
l_nor<-lm(gch_nor~gpa_nor)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
minu <- sum(x*w) / sum(w)
final <- sum(w*(x-minu)^2)
c(minu, final)
mu <- c(0.1471, 1.077, 0.0025, 0.300)
for (v in mu)
{print( c(v, sum(w*(x-v)^2)) )}
manipulate
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
plot(y,x)
b1 <- cor(x,y)*sd(y)/sd(x)
b0 <- mean(y) - b1 * mean(x)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library("caret")
library(caret)
install.packages("caret")
data(AlzheimerDisease)
data(AlzheimerDisease)
data("AlzheimerDisease")
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
suppressMessages(library(caret))
set.seed(33833)
rfmodel <- suppressMessages(train(y~., data=vowel.train, method="rf"))
gbmmodel <- suppressMessages(train(y~., data=vowel.train, method="gbm"))
library(ElemStatLearn)
library("ElemStatLearn")
install.packages("ElemStatLearn")
data(vowel.train)
data("vowel.train")
set.seed(3523)
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
results <- c(accsvm[2], accsvmRadial[2], accsvmLinear[2], accsvmPoly[2], accsvmRadial[2], accsvmRadialCost[2])
library(swirl)
swirl()
fit<-lm(child~parent,galton)
sum(sqdres/n-2)
sum(fit$residuals^2) / (n - 2))
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu<-mean(galton$child)
sTot<-sum((galton$child-mu)^2)
sRes <- deviance(fit)
1-(sRes/sTot)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ ones + parent, galton)
lm(child ~ 1, galton)
view(trees)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
install.packages("rmarkdown")
library(datasets); data(swiss); require(stats); require(graphics)
sum(swiss)
head(swiss)
pairs(swiss,panel=panel.smooth, main="Swiss data", col = 3 + (swiss$Catholic>50))
summary(lm(Fertility~ .,data=swiss))
data(mtcars)
head(mtcars)
tail(mtcars)
summary(mtcars)
?(mtcars)
?mtcars
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$am, pch=19, col=”green”
lm1<-lm(mtcars$mpg~mtcars$am)
lm1<-lm(mtcars$mpg~mtcars$am)
lm1
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$gear, pch=19, col=”green”
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$gear, pch=19, col=”blue”
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$gear, pch=19, col = ”blue”
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$gear, pch=19, col = 'blue'
)
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$gear, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$cyl, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$gear, mtcars$mpg, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$wt, mtcars$mpg, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$wt, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$mpg, mtcars$cyl, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$gear, mtcars$mpg, pch=19, col = 'blue')
lm1<-lm(mtcars$mpg~mtcars$am)
plot(mtcars$gear, mtcars$mpg, pch=19, col = 'blue')
summary(lm(mtcars$mpg.-1,data=dat))$coef
summary(lm(mtcars$mpg.-1,data=mtcars))$coef
summary(lm(mtcars$mpg.-1))$coef
summary(lm(mtcars$mpg.-1,data=dat))$coef
summary(lm(mtcars$mpg.-1,data=num))$coef
summary(lm(mtcars$mpg.-1,data=mtcars))$coef
?lm
summary(lm(mpg ~ .-1,data=mtcars))$coef
fit<-lm(mpg~.-1,data=mtcars);plot(predict(fit),resid(fit),pch='.')
library(rcharts)
install.packages(shiny)
library(shiny)
library("shiny")
install.packages("shiny")
library(shiny)
shinyUI(pageWithSidebar(headerPanel("Data science FTW!"), sidebarPanel(h3('Sidebar text')), mainPanel(h3('Main Panel text'))))
shinyServer(function(input, output){})
ftype(lm)
install.packages("pryr")
library(pryr)
ftype(show)
ftype(lm)
ftype(colSums)
ftype(dgamma)
shinyServer()
install.packages("shiny")
library(shiny)
shinyServer(
function(input, output){
output$text1<-renderText({input$text1})
output$text2<-renderText({input$text2})
output$text3<-renderText({
input$goButton
isolate(past(input$text1, input$text2))
})
}
)
shinyServer(
function(input, output){
output$text1<-renderText({input$text1})
output$text2<-renderText({input$text2})
output$text3<-renderText({
input$goButton
isolate(past(input$text1, input$text2))
})
}
)
shinyUI(pageWithSidebar(
headerPanel("Hello Shiny!"),
sidebarPanel(
textInput(inputId="text1", label = "Input Text1"),
textInput(inputId="text2", label = "Input Text2"),
actionButton("goButton", "Go!")
),
mainPanel(
p('Output text1'),
textOutput('text1'),
p('Output text2'),
textOutput('text2'),
p('Output text3'),
textOutput('text3')
)
))
shinyServer(
function(input, output){
output$text1<-renderText({input$text1})
output$text2<-renderText({input$text2})
output$text3<-renderText({
input$goButton
isolate(past(input$text1, input$text2))
})
}
)
shiny::runApp('Data Science')
shiny::runApp('Data Science')
shiny::runApp('Data Science')
shiny::runApp('Data Science')
shiny::runApp('Data Science')
library(UsingR)
library(manipulate)
shiny::runApp('Data Science')
shiny::runApp('Data Science')
myHist<-function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0,150),col="red",lwd=5)
mse<-mean((galton$child - mu)^2)))
}
myHist<-function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse<-mean((galton$child - mu)^2)
text(63, 150, paste("mu =", mu))
text(63, 140, paste("MSE = ", round(mse,2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
shiny::runApp('Data Science')
library(manipulate)
myHist<-function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse<-mean((galton$child - mu)^2)
text(63, 150, paste("mu =", mu))
text(63, 140, paste("MSE = ", round(mse,2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(kernlab)
data(spam)I
head(spam)
install.packages("kernlab")
library(kernlab)
data(spam)I
head(spam)
library(kernlab)
data(spam)
head(spam)
Prediction <- ifelse(spam$your > 0.5,"spam","nonspam")
table(prediction,spam$type)/lenght(spam$type)
table(prediction,spam$type)/length(spam$type)
prediction <- ifelse(spam$your > 0.5,"spam","nonspam")
table(prediction,spam$type)/length(spam$type)
shiny::runApp('Data Science')
set.seed(333)
smallSpam<-spam[sample(dim(spam)[1],size=10),]
spamLabel <- (smallSpam$type=="spam")*1 + 1
plot(smallSpam$capitalAve,col=spamLabel)
install.packages("caret")
library(caret); library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
set.seed(32343)
modelFit<-train(type~.,data=training, method="glm")
modelFit
set.seed(32343)
modelFit<-train(type ~.,data=training, method="glm")
modelFit
set.seed(32343)
modelFit <-train(type ~.,data=training, method="glm")
modelFit
head(training)
library(caret); library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
set.seed(32323)
folds ,- createFolds(y=spam$type,k=10, list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds <- createFolds(y=spam$type,k=10, list=TRUE,returnTrain=TRUE)
sapply(folds,length)
set.seed(32323)
tme <- 1:1000
folds <-createTimeSlices(y=tme,initialWindow=20, horizon=10)
names(folds)
folds$train[[1]]
library(caret); library(kernlab);data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
modelFit<-train(type ~.,data=training,method="glm")
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
install.packages("kernlab")
library(caret); library(kernlab);data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
modelFit<-train(type ~.,data=training,method="glm")
warnings()
args(train.default)
function(x, y, method = "rf", preProcess = NULL, ..., weights = NULL,
metric = ifelse(is.factor(y), "Accuracy", "RMSE"), maximize = ifelse(metric ==
"RMSE", FALSE, TRUE), trControl = trainControl(), tuneGrid = NULL, tuneLength = 3)
NULL
preObj <- PREProcess(training[,-58],method=c("center","scale"))
trainCapAveS<- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS<- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
library(caret)
library (kernlab)
data (spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
testCapAveS<-predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
preObj <-preProcess(training,[,-58],method=c("BoxCox"))
trainCapAveS<-predict(preObj,training[,-58])$capitalAve
par(mfrow=C(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
preObj <-preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS<-predict(preObj,training[,-58])$capitalAve
par(mfrow=C(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
setwd("~/Data Science/Machine Learning")
---
title: "Practical Machine Learning Project"
author: "BRohde"
date: "Sunday, August 16, 2015"
---
##Can Accelerometers Indicate Proper Form During Unilateral Dumbbell Biceps Curl?
##Synopsis
The goal of this project was to predict the manner in which six participants performed unilateral dumbbell bicep curls while wearing accelerometers (FitBit, Jawbone Up, and Nike FuelBand) by using the Weight Lifting Exercises Dataset provided at http:/groupware.les.inf.puc-rio.br/har from the paper Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
The six participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).
To accomplish this goal the Weight Lifting Exercises Dataset was analysed and processed to eliminate NA's and focus on relevant predictor variables excluding the "classe" variable in the training set.  The model was built using the Random Forest algorithm on the variables that were independent (maximum correlation < 60%).  A simple k-fold cross-validation control was used.  The expected out of sample error was estimated to be 2% or less.  20 test observations were then predicted using the model.
##Data Processing - Loading and Processing the Raw Data
Download and load the data.  Files were downloaded from the Practical Machine Language Coursera website from the following links:
The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
```{r}
#install.packages("caret")
#install.packages("knitr")
#install.packages("corrplot")
#install.packages("ggplot2")
#install.packages("randomForest")
#install.packages("rpart.plot")
#setwd("~/Data Science")
getwd()
library(knitr)
knit2html("PMLProject.RMD")
```
```{r}
training<-read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
```
```{r}
testingkey<-read.csv("pml-testing.csv", na.strings = c("NA", "#DIV/0!", ""))
dim(training)
dim(testingkey)
head(training, n=2)
```
Remove variables that have a majority of NA values and are not relevant to this project.
```{r, echo=FALSE}
remove = c('X', 'user_name', 'raw_timestamp_part_1','raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')
training<-training[,-which(names(training)%in% remove)]
dim(training)
data <- apply(!is.na(training), 2, sum) > 19621
training <- training [, data]
```
Verify for near zero variance.
```{r, echo=FALSE}
library(caret)
nzvar<- nearZeroVar(training)
if(length(nzvar)>0) {
training<-training[, -nzvar]
}
dim(training)
```
No variables had near zero variance.
Cross validation is required so the training set needs to be partitioned into a "training set" (75%) and a "test set" (25%). Note, the caret package will need to be installed from CRAN if it is not loaded. (install.packages("caret") in R)
```{r, echo=FALSE}
set.seed(789123)
inTrain<-createDataPartition(y=training$classe, p=0.75, list=FALSE)
training1<-training[inTrain,]
testing1<-training[-inTrain,]
dim(training1)
dim(testing1)
```
To assist in focusing on variables that are key predictors of Bicep Curl form an initial randomForest is run on the training1 dataset with a variable importance plot result.
```{r, echo=TRUE, fig.height=8}
library(randomForest)
set.seed(3457)
RFModel<-randomForest(classe~., data=training1, importance=TRUE, ntree=100)
varImpPlot(RFModel)
```
From the Accuracy and Gini graph results above, the top 9 variables are selected for model building.  The 9 variables include: yaw_belt, pitch_belt, roll_belt, magnet_forearm_z, magnet_dumbell_z, magnet_dumbell_y, pitch_forearm, gyros_arm_y, accel_dumbbell_Z.
Next the 9 covariates are analyzed for correlations.
```{r, echo=FALSE}
correlation = cor(training1[,c("yaw_belt","roll_belt","pitch_belt", "magnet_forearm_z", "magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm", "gyros_arm_y", "accel_dumbbell_z")])
diag(correlation) <- 0
which(abs(correlation)>0.75, arr.ind=TRUE)
```
There is a correlation over 75% between yaw_belt and roll_belt.  By removing roll_belt and re-running the correlation  script (see below) it is determined the remaining eight variables provide a maximum correlation of 54% which is indicative of independence of the covariates.
```{r, echo=FALSE}
correlation = cor(training1[,c("yaw_belt","pitch_belt", "magnet_forearm_z", "magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm", "gyros_arm_y", "accel_dumbbell_z")])
diag(correlation) <- 0
which(abs(correlation)>0.75, arr.ind=TRUE)
max(correlation)
```
Running a tree classifier on the training1 data; roll_belt is listed as the first discriminant among the covariates which indicates that roll_belt should be included in the prediction model and yaw_belt removed.
```{r, echo=FALSE}
library(rpart.plot)
treeModel<-rpart(classe~., data=training1, method="class")
prp(treeModel)
```
Running the correlation script again including roll_belt and excluding yaw_belt produces a maximum correlation of 54% which is still indicative of independent covariates.
```{r, echo=FALSE}
correlation = cor(training1[,c("roll_belt","pitch_belt", "magnet_forearm_z", "magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm", "gyros_arm_y", "accel_dumbbell_z")])
diag(correlation) <- 0
which(abs(correlation)>0.75, arr.ind=TRUE)
max(correlation)
```
##Prediction Model
The most significant eight variables are used from the initial Random Forest classification which include: roll_belt, pitch_belt, magnet_forearm_z, magnet_dumbbell_z, magnet_dumbbell_y, pitch_forearm, gyros_arm_y, and accel_dumbbell_y. For cross-validation a 2-fold cross-validation control is chosen to maximize run time on this large data set.  The train() function from the caret package is used for this Random Forest algorithm.
```{r}
controltwo<-trainControl(method="cv",2)
RFcModel<-train(classe ~ roll_belt + pitch_belt + magnet_forearm_z + magnet_dumbbell_z + magnet_dumbbell_y + pitch_forearm + gyros_arm_y + accel_dumbbell_z, data=training1, method="rf", trControl=controltwo, ntree=250)
RFcModel
```
From the caret package the confusionMatrix()function is applied on the test set (testing1) to determine the model's accuracy.
```{r}
predictions<- predict(RFcModel, newdata=testing1)
confusionMat <- confusionMatrix(predictions, testing1$classe)
confusionMat
accuracy <- postResample(predictions, testing1$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(testing1$classe, predictions)$overall[1])
oose
```
The accuracy is 98.5% which substantiates using the smaller subset of significant variables.  The Random Forest algorithm's out-of-sample error rate is calculated as follows: 100% - Prediction Accuracy of .985   = 1.40% which is below the assumed out-of-sample error of 2%.
##Practical Machine Learning Course Submission
The following 20 observations from the course project submission page are predicted using the Random Forest Algorithm.
```{r}
final<-predict(RFcModel, newdata=testingkey)
final
```
Results submitted to Practical Machine Language course.
```{r}
answers <- final
pml_write_files = function (x){
n = length (x)
for(i in 1:n){
filename = paste0("problem_id", i,".txt")
write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
}
}
pml_write_files(answers)
```
title: "Practical Machine Learning Project"
author: "BRohde"
date: "Sunday, August 16, 2015"
---
##Can Accelerometers Indicate Proper Form During Unilateral Dumbbell Biceps Curl?
##Synopsis
The goal of this project was to predict the manner in which six participants performed unilateral dumbbell bicep curls while wearing accelerometers (FitBit, Jawbone Up, and Nike FuelBand) by using the Weight Lifting Exercises Dataset provided at http:/groupware.les.inf.puc-rio.br/har from the paper Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
The six participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).
To accomplish this goal the Weight Lifting Exercises Dataset was analysed and processed to eliminate NA's and focus on relevant predictor variables excluding the "classe" variable in the training set.  The model was built using the Random Forest algorithm on the variables that were independent (maximum correlation < 60%).  A simple k-fold cross-validation control was used.  The expected out of sample error was estimated to be 2% or less.  20 test observations were then predicted using the model.
##Data Processing - Loading and Processing the Raw Data
Download and load the data.  Files were downloaded from the Practical Machine Language Coursera website from the following links:
The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
```{r}
install.packages("caret")
install.packages("knitr")
install.packages("corrplot")
